{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return (1.2 * np.sin(np.pi * x) - np.cos(2.4 * np.pi * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    # define the neural network structure\n",
    "    def __init__(self, n_hidden, device):\n",
    "        super(net, self).__init__()\n",
    "        self.layer1 = nn.Linear(1, n_hidden).to(torch.device(device))\n",
    "        self.layer2 = nn.Linear(n_hidden, 1).to(torch.device(device))\n",
    "\n",
    "    # define the data process inside our layer\n",
    "    def forward(self, x, device):\n",
    "        x = torch.tanh(self.layer1(x)).to(device)\n",
    "        x = self.layer2(x).to(device)\n",
    "        return x\n",
    "    \n",
    "    def train(self, train_inputs, train_labels, \n",
    "              val_inputs, val_labels, \n",
    "              device='cpu', train_type='gd', \n",
    "              num_max_epoch=1000, lr=0.01, \n",
    "              stop_val=0.01):\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.SGD(self.parameters(), lr)\n",
    "        \n",
    "        if(train_type == 'gd'):\n",
    "            # train the model\n",
    "            temp_running_loss = 0.0\n",
    "            running_loss = 0.0\n",
    "            for epoch in range(num_max_epoch):\n",
    "                # predict the output\n",
    "                tprediction = self(train_inputs, device)     \n",
    "                tloss = criterion(tprediction, train_labels)\n",
    "                self.train_loss.append(tloss.item())\n",
    "                optimizer.zero_grad()\n",
    "                tloss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # validate the outputs\n",
    "                vprediction = self(val_inputs, device)\n",
    "                vloss = criterion(vprediction, val_labels)\n",
    "                self.val_loss.append(vloss.item())\n",
    "                \n",
    "                # print status\n",
    "                print('\\rGD epoch: {}\\tLoss =  {:.3f} vLoss =  {:.3f}'.format(epoch, tloss, vloss), end=\"\")\n",
    "\n",
    "                \n",
    "        elif(train_type == 'sgd'):            \n",
    "            for epoch in range(num_max_epoch):\n",
    "                training_loss = 0.0\n",
    "                validation_loss = 0.0\n",
    "                \n",
    "                for x_i, y_i in zip(train_inputs, train_labels):\n",
    "                    pred_i = self(x_i, device)\n",
    "                    tloss = criterion(pred_i, y_i)\n",
    "                    optimizer.zero_grad()   \n",
    "                    tloss.backward()         \n",
    "                    optimizer.step()\n",
    "                    training_loss += tloss.item()\n",
    "                \n",
    "                for x_i, y_i in zip(val_inputs, val_labels):\n",
    "                    pred_i = self(x_i, device)\n",
    "                    vloss = criterion(pred_i, y_i)\n",
    "                    validation_loss += vloss.item()\n",
    "                \n",
    "                training_loss = training_loss/len(train_inputs)\n",
    "                validation_loss = validation_loss/len(val_inputs)\n",
    "                self.train_loss.append(training_loss)\n",
    "                self.val_loss.append(validation_loss)\n",
    "                print('\\rSGD epoch: {}\\tLoss =  {:.3f} vLoss =  {:.3f}'.format(epoch, training_loss, validation_loss), end=\"\") \n",
    "                    \n",
    "                    \n",
    "        elif(train_type == 'mbgd'):\n",
    "            batch_size = 16\n",
    "            train_n_batches = int(len(train_inputs) / batch_size) \n",
    "            val_n_batches = int(len(val_inputs) / batch_size) \n",
    "            print(train_n_batches)\n",
    "            print(val_n_batches)\n",
    "            for epoch in range(num_max_epoch):\n",
    "                training_loss = 0.0\n",
    "                validation_loss = 0.0\n",
    "                \n",
    "                for batch in range(train_n_batches):\n",
    "                    batch_X, batch_y = train_inputs[batch*batch_size:(batch+1)*batch_size], train_labels[batch*batch_size:(batch+1)*batch_size]\n",
    "                    prediction = self(batch_X, device)\n",
    "                    tloss = criterion(prediction, batch_y)\n",
    "                    training_loss += tloss.item()\n",
    "                    optimizer.zero_grad()\n",
    "                    tloss.backward() \n",
    "                    optimizer.step() \n",
    "                    \n",
    "                for batch in range(val_n_batches):\n",
    "                    batch_X, batch_y = val_inputs[batch*batch_size:(batch+1)*batch_size], val_labels[batch*batch_size:(batch+1)*batch_size]\n",
    "                    prediction = self(batch_X, device)\n",
    "                    vloss = criterion(prediction, batch_y)\n",
    "                    validation_loss += vloss.item()\n",
    "                    \n",
    "                training_loss = training_loss/train_n_batches\n",
    "                validation_loss = validation_loss/val_n_batches\n",
    "                self.train_loss.append(training_loss)\n",
    "                self.val_loss.append(validation_loss)\n",
    "                print('\\rMB GD epoch: {}\\tLoss =  {:.3f} vLoss =  {:.3f} '.format(epoch, training_loss, validation_loss), end=\"\")\n",
    "                    \n",
    "                    \n",
    "    def test(self, test_inputs, test_labels, device='cpu'):\n",
    "        self.test_loss = 0\n",
    "        self.test_values = []\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        for x_i, y_i in zip(test_inputs, test_labels):\n",
    "            pred_i = self(x_i, device)\n",
    "            loss = criterion(pred_i, y_i)\n",
    "            self.test_loss += loss.item()\n",
    "            self.test_values.append(pred_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lines(datas, \n",
    "               legends,\n",
    "               title='Title',\n",
    "               xlabel='xlabel',\n",
    "               ylabel='ylabel'):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.grid()\n",
    "    for i in range(len(legends)):\n",
    "        plt.plot(datas[i])\n",
    "        plt.legend(legends)\n",
    "        plt.title(title, fontsize=30)\n",
    "        plt.xlabel(xlabel, fontsize=20)\n",
    "        plt.ylabel(ylabel, fontsize=20)\n",
    "        plt.xticks(fontsize=15)\n",
    "        plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(datas,\n",
    "              legends, \n",
    "              title='Title',\n",
    "              xlabel='xlabel',\n",
    "              ylabel='ylabel'):\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))    \n",
    "    x = datas\n",
    "    xi = list(range(len(legends)))\n",
    "\n",
    "    plt.grid()\n",
    "    plt.xticks(xi, legends, fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.bar(xi, x)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.xlabel(xlabel, fontsize=20)\n",
    "    plt.ylabel(ylabel, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_all(directory, trained_nets, hidden_net_sets):\n",
    "#     for i, net_i in enumerate(trained_nets):\n",
    "#         torch.save(net_i, f\"{directory}model_100000_gd_{str(hidden_net_sets[i])}.pt\")\n",
    "\n",
    "#         with open(f'{directory}model_train_loss_100000_{str(hidden_net_sets[i])}.txt', 'w') as f:\n",
    "#             for item in net_i.train_loss:\n",
    "#                 f.write(\"%s\\n\" % item)\n",
    "\n",
    "#         with open(f'{directory}model_val_loss_100000_{str(hidden_net_sets[i])}.txt', 'w') as f:\n",
    "#             for item in net_i.val_loss:\n",
    "#                 f.write(\"%s\\n\" % item)\n",
    "\n",
    "def read_all(directory, epoch, hidden_net_sets, device):\n",
    "    all_model = []\n",
    "    all_train_loss = []\n",
    "    all_val_loss = []\n",
    "    \n",
    "    for i, net_i in enumerate(hidden_net_sets):\n",
    "        model = net(net_i * net_i, device)\n",
    "#         model.load_state_dict(torch.load(f\"{directory}model_100000_gd_{str(net_i)}.pt\"))\n",
    "        model = torch.load(f\"{directory}model_{str(epoch)}_gd_{str(net_i)}.pt\", map_location=device)\n",
    "        all_model.append(model)\n",
    "        \n",
    "        f = open(f\"model_train_loss_{str(epoch)}_{str(net_i)}.txt\", \"r\")\n",
    "        contents = f.read()\n",
    "        new_arr = np.array(contents.splitlines(), dtype=np.float32).reshape((-1, 1))\n",
    "        all_train_loss.append(new_arr)\n",
    "        f.close()\n",
    "        \n",
    "        f = open(f\"model_val_loss_{str(epoch)}_{str(net_i)}.txt\", \"r\")\n",
    "        contents = f.read()\n",
    "        new_arr = np.array(contents.splitlines(), dtype=np.float32).reshape((-1, 1))\n",
    "        all_val_loss.append(new_arr)\n",
    "        f.close()\n",
    "        \n",
    "    return all_model, all_train_loss, all_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = torch.Tensor(np.arange(-2, 2, 0.05).astype(np.float32)).reshape(-1, 1)\n",
    "test_in = torch.Tensor(np.arange(-2, 2, 0.01).astype(np.float32)).reshape(-1, 1)\n",
    "train_out = func(train_in).reshape(-1, 1).to(device)\n",
    "test_out = func(test_in).reshape(-1, 1).to(device)\n",
    "train_in = train_in.to(device)\n",
    "test_in = test_in.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_nets = []\n",
    "train_losses = []\n",
    "train_epochs = []\n",
    "test_losses = []\n",
    "hidden_net_sets = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_net in hidden_net_sets:\n",
    "    network = net(hidden_net, device)\n",
    "    network.train(train_in, train_out,\n",
    "                  test_in, test_out,\n",
    "                  device=device, train_type='gd',\n",
    "                  num_max_epoch=100000,\n",
    "                  lr=0.01, stop_val=0.01)\n",
    "    \n",
    "    trained_nets.append(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_train = 100000\n",
    "trained_nets, train_losses, test_losses = read_all('./', epoch_train, hidden_net_sets, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot models losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines([loss for loss in train_losses], \n",
    "           hidden_net_sets,\n",
    "           title='Training in various number of neurons',\n",
    "           xlabel='Epochs',\n",
    "           ylabel='Train Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot train and test losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr = np.array([loss[-1] for loss in train_losses])\n",
    "plot_bars(new_arr.reshape(-1), \n",
    "          hidden_net_sets, \n",
    "          title='Train loss value of each neurons number',\n",
    "          xlabel='Neurons',\n",
    "          ylabel='Loss')\n",
    "\n",
    "new_arr = np.array([loss[-1] for loss in test_losses])\n",
    "plot_bars(new_arr.reshape(-1), \n",
    "          hidden_net_sets, \n",
    "          title='Test loss value of each neurons number',\n",
    "          xlabel='Neurons',\n",
    "          ylabel='Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figures(datas, \n",
    "                 legend=['Model', 'Reference'], \n",
    "                 title='Title', \n",
    "                 xlabel='xLabel', ylabel='yLabel', \n",
    "                 xi=[0, 100, 200, 300, 400, 500, 600],\n",
    "                 x=[-3, -2, -1, 0, 1, 2, 3]):\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.grid()\n",
    "    for i, data in enumerate(datas):\n",
    "        plt.plot(data)\n",
    "        plt.legend(legend)\n",
    "        plt.title(title, fontsize=30)\n",
    "        plt.xlabel(xlabel, fontsize=20)\n",
    "        plt.ylabel(ylabel, fontsize=20)\n",
    "        plt.xticks(xi, x, fontsize=20)\n",
    "        plt.yticks(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_try = test_in\n",
    "# input_try = np.arange(-2, 2, 0.01, dtype=np.float32)\n",
    "output_try = func(input_try).to(device)\n",
    "input_try = input_try.to(device)\n",
    "hidden_net_sets = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\n",
    "for i, net_ser in enumerate(trained_nets):\n",
    "    trained_nets[i].test(input_try, output_try)\n",
    "    out = trained_nets[i].test_values\n",
    "    out = np.array(out, dtype=np.float)\n",
    "    \n",
    "    plot_figures([out, output_try], \n",
    "             legend=['Reference', 'Model'],\n",
    "             title=f\"Test losses over a hidden layers with {hidden_net_sets[i]} neuron(s)\", \n",
    "             xlabel='Points', ylabel='Outputs',\n",
    "             xi=[0, 100, 200, 300, 400],\n",
    "             x=[-2, -1, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Train for detailed phase for 7-100 neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read trained models (7-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_train = 1000000\n",
    "additional_hidden_net_sets = [7, 8, 9, 10, 20, 50, 100]\n",
    "trained_nets, train_losses, test_losses = read_all('./', epoch_train, additional_hidden_net_sets, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot models losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hidden_net_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines([loss for loss in train_losses], \n",
    "           additional_hidden_net_sets,\n",
    "           title='Training in various number of neurons',\n",
    "           xlabel='Epochs',\n",
    "           ylabel='Train Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr = np.array([loss[-1] for loss in train_losses])\n",
    "plot_bars(new_arr.reshape(-1), \n",
    "          additional_hidden_net_sets, \n",
    "          title='Train loss value of each neurons number',\n",
    "          xlabel='Neurons',\n",
    "          ylabel='Loss')\n",
    "\n",
    "new_arr = np.array([loss[-1] for loss in test_losses])\n",
    "plot_bars(new_arr.reshape(-1), \n",
    "          additional_hidden_net_sets, \n",
    "          title='Test loss value of each neurons number',\n",
    "          xlabel='Neurons',\n",
    "          ylabel='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_try = test_in\n",
    "# input_try = np.arange(-2, 2, 0.01, dtype=np.float32)\n",
    "output_try = func(input_try).to(device)\n",
    "input_try = input_try.to(device)\n",
    "for i, net_ser in enumerate(trained_nets):\n",
    "    trained_nets[i].test(input_try, output_try)\n",
    "    out = trained_nets[i].test_values\n",
    "    out = np.array(out, dtype=np.float)\n",
    "    \n",
    "    plot_figures([out, output_try], \n",
    "             legend=['Reference', 'Model'],\n",
    "             title=f\"Test losses over a hidden layers with {additional_hidden_net_sets[i]} neuron(s)\", \n",
    "             xlabel='Points', ylabel='Outputs',\n",
    "             xi=[0, 100, 200, 300, 400],\n",
    "             x=[-2, -1, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input -3 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_net_sets = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\n",
    "for i, net in enumerate(trained_nets):\n",
    "    a, b = net(torch.tensor([-3.0]), device).item(), net(torch.tensor([3.0]), device).item()\n",
    "    c, d = net(torch.tensor([-1.0]), device).item(), net(torch.tensor([1.0]), device).item()\n",
    "    e = net(torch.tensor([0.0]), device).item()\n",
    "    print(f\"Result for {hidden_net_sets[i]} is :\")\n",
    "    print(f\"(-3) = {round(a,3)}\")\n",
    "    print(f\"(-1) = {round(c,2)}\")\n",
    "    print(f\"(0) = {round(e,2)}\")\n",
    "    print(f\"(+1) = {round(d,2)}\")\n",
    "    print(f\"(+3) = {round(b,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_try = test_in\n",
    "input_try = np.arange(-3, 3, 0.01, dtype=np.float32).reshape(-1, 1)\n",
    "output_try = func(input_try).reshape(-1, 1)\n",
    "input_try = torch.Tensor(input_try).to(device)\n",
    "output_try = torch.Tensor(output_try).to(device)\n",
    "hidden_net_sets = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\n",
    "for i, net_ser in enumerate(trained_nets):\n",
    "    trained_nets[i].test(input_try, output_try)\n",
    "    out = trained_nets[i].test_values\n",
    "    out = np.array(out, dtype=np.float)\n",
    "    \n",
    "    plot_figures([output_try, out], \n",
    "             legend=['Reference', 'Model'],\n",
    "             title=f\"Test losses over a hidden layers with {hidden_net_sets[i]} neuron(s)\", \n",
    "             xlabel='Points', ylabel='Outputs',\n",
    "             xi=[0, 100, 200, 300, 400, 500, 600],\n",
    "             x=[-3, -2, -1, 0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input -3 and 3 v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_hidden_net_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, net in enumerate(trained_nets):\n",
    "    a, b = net(torch.tensor([-3.0]), device).item(), net(torch.tensor([3.0]), device).item()\n",
    "    c, d = net(torch.tensor([-1.0]), device).item(), net(torch.tensor([1.0]), device).item()\n",
    "    e = net(torch.tensor([0.0]), device).item()\n",
    "    print(f\"Result for {additional_hidden_net_sets[i]} is :\")\n",
    "    print(f\"(-3) = {round(a,3)}\")\n",
    "    print(f\"(-1) = {round(c,2)}\")\n",
    "    print(f\"(0) = {round(e,2)}\")\n",
    "    print(f\"(+1) = {round(d,2)}\")\n",
    "    print(f\"(+3) = {round(b,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_try = test_in\n",
    "input_try = np.arange(-3, 3, 0.01, dtype=np.float32).reshape(-1, 1)\n",
    "output_try = func(input_try).reshape(-1, 1)\n",
    "input_try = torch.Tensor(input_try).to(device)\n",
    "output_try = torch.Tensor(output_try).to(device)\n",
    "for i, net_ser in enumerate(trained_nets):\n",
    "    trained_nets[i].test(input_try, output_try)\n",
    "    out = trained_nets[i].test_values\n",
    "    out = np.array(out, dtype=np.float)\n",
    "    \n",
    "    plot_figures([output_try, out], \n",
    "             legend=['Reference', 'Model'],\n",
    "             title=f\"Test losses over a hidden layers with {additional_hidden_net_sets[i]} neuron(s)\", \n",
    "             xlabel='Points', ylabel='Outputs',\n",
    "             xi=[0, 100, 200, 300, 400, 500, 600],\n",
    "             x=[-3, -2, -1, 0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B & C - Using trainlm and trainbr algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2-2 === Trainlm Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using trainlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_loss = [1.0149, 1.1406, 0.3574, 0.3475, 0.3841, 0.1060, 0.0155, 6.2299e-05, 0.0127, 1.1469e-05, 0.0155, 0.3382, 0.7501]\n",
    "Test_loss = [0.9999, 1.1464, 0.3496, 0.3492, 0.3859, 0.1068, 0.0156, 3.1414e-05, 0.0129, 1.1649e-05, 0.0151, 0.3343, 0.6907]\n",
    "hidden_net_sets = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_bars(Train_loss, \n",
    "          hidden_net_sets, \n",
    "          title='Train loss value of each neurons number (trainlm)',\n",
    "          xlabel='Neurons',\n",
    "          ylabel='Loss')\n",
    "\n",
    "plot_bars(Test_loss, \n",
    "          hidden_net_sets, \n",
    "          title='Test loss value of each neurons number (trainlm)',\n",
    "          xlabel='Neurons',\n",
    "          ylabel='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2-3 === Trainbr Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_loss = [1.0986, 1.1507, 1.2035, 1.0968, 0.1144, 1.1006, 4.0383e-04, 1.1905, 1.4337e-04, 5.1526e-07, 5.1346e-08, 7.2183e-11, 2.2767e-08]\n",
    "Test_loss = [1.0995, 1.1518, 1.2091, 1.0977, 0.1154, 1.1010, 3.7432e-04, 1.1945, 1.2825e-04, 5.0316e-07, 1.5869e-07, 1.8761e-10, 1.3317e-08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_bars(Train_loss, \n",
    "          hidden_net_sets, \n",
    "          title='Train loss value of each neurons number (trainbr)',\n",
    "          xlabel='Neurons',\n",
    "          ylabel='Loss')\n",
    "\n",
    "plot_bars(Test_loss, \n",
    "          hidden_net_sets, \n",
    "          title='Test loss value of each neurons number (trainbr)',\n",
    "          xlabel='Neurons',\n",
    "          ylabel='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
